# **Results**

## **1. Overview of Experimental Results**

The cattle breed classification model was trained and evaluated using a multi-class image dataset containing approximately 60 Indian bovine breeds, with around 100 images per breed. The model was implemented using transfer learning with EfficientNetV2 architecture and trained in two phases: feature extraction and fine-tuning. Evaluation was performed using validation accuracy, class-wise metrics, and confusion matrix analysis.

The results demonstrate that deep learning–based image classification can effectively learn discriminative visual features for cattle breed identification, although performance varies across classes depending on image quality, dataset balance, and breed similarity.

---

# **2. Training Performance**

During training, the model showed steady improvement in training accuracy while validation accuracy improved more gradually. The Early Stopping mechanism automatically halted training when validation loss stopped improving, preventing overfitting and reducing unnecessary computation time.

Two-stage training contributed to better convergence:

## Phase 1 — Frozen Base Model

* Only classification layers trained
* Rapid early learning
* Stable convergence
* Lower risk of overfitting

## Phase 2 — Fine Tuning

* Top layers of base network unfrozen
* Lower learning rate used
* Improved feature specialization
* Better class separation

This staged approach improved performance compared to single-phase training.

---

# **3. Validation Accuracy**

The final validation accuracy achieved in experiments ranged between:

```
~70% to ~85% (depending on class subset and training configuration)
```

Key influencing factors:

* Number of classes (60 classes increases difficulty)
* Limited images per class (~100)
* Visual similarity between some breeds
* Variation in image quality and pose

It is important to note that multi-class classification accuracy decreases as the number of classes increases. For a 60-class problem with limited data, the achieved performance is considered reasonable and demonstrates strong learning behavior.

---

# **4. Classification Report Metrics**

A detailed classification report was generated using:

* Precision
* Recall
* F1-score per breed

## Observations:

### High-performing classes:

* Breeds with distinct coat color or horn shape
* Breeds with consistent image backgrounds
* Classes with higher image clarity

These classes showed:

* High precision
* High recall
* Strong F1-scores

---

### Lower-performing classes:

* Breeds with similar color patterns
* Breeds with mixed lighting conditions
* Classes with noisy or low-resolution images

These showed:

* Lower recall
* Higher confusion with visually similar breeds

---

# **5. Confusion Matrix Analysis**

A confusion matrix was plotted to analyze class-wise prediction behavior.

## Key findings:

* Most misclassifications occurred between:

  * visually similar breeds
  * similar body color patterns
  * similar horn structures

* Distinct breeds were classified correctly with high confidence.

The confusion matrix revealed that the model learned meaningful visual features but struggled where inter-class visual similarity was high.

This insight suggests that additional training data and more varied images would improve separation.

---

# **6. Effect of Data Augmentation**

Data augmentation significantly improved validation performance.

Without augmentation:

* Faster overfitting
* Lower validation accuracy

With augmentation:

* Better generalization
* Reduced overfitting
* More stable validation curves

Augmentation allowed the model to handle:

* rotation
* zoom
* flipped poses
* lighting variation

---

# **7. Effect of Fine Tuning**

Fine-tuning the upper layers of EfficientNetV2 produced measurable improvement compared to frozen-base-only training.

Observed improvements included:

* Better class boundary learning
* Increased validation accuracy
* Improved F1 scores
* Reduced confusion for mid-similarity breeds

Fine tuning proved essential for domain adaptation from ImageNet to cattle images.

---

# **8. Prediction System Results**

The trained model was integrated into an interactive prediction interface using Gradio.

## Real-time prediction results:

* Image upload works correctly
* Breed prediction returned instantly
* Confidence scores displayed
* Works reliably for clear cattle images
* Performance decreases on blurred or partial images

This confirms that the trained model is deployable in practical usage scenarios.

---

# **9. Performance Limitations Observed**

Despite strong results, some limitations were observed:

* Class imbalance affects recall
* Similar breeds cause confusion
* Small dataset per class limits deep specialization
* Background clutter affects predictions
* Non-side-view cattle images reduce accuracy

These limitations are data-driven rather than architecture-driven.

---

# **10. Overall Result Summary**

The project successfully demonstrates that:

✅ Deep learning can classify Indian cattle breeds
✅ Transfer learning significantly improves performance
✅ Fine-tuning increases accuracy
✅ Data augmentation improves generalization
✅ Multi-class livestock classification is feasible
✅ Real-time prediction interface is deployable

The results validate the technical feasibility of automated cattle breed identification and show strong potential for further improvement with expanded datasets and additional training.

---


